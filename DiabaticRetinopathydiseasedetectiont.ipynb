{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fexsv5Vm0CjH"
      },
      "source": [
        "# DiabaticRetinopathydiseasedetectiont"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eb-F1t2NgR-7"
      },
      "source": [
        "Instruction:\n",
        "1. install dependencies like \n",
        "    tensorflow, keras for CNN modeling\n",
        "    PILLOW and cv2 for image processing\n",
        "    Numpy mathplot , skkitplot sklearn io for data and image transformation and  result graph plots etc\n",
        "2. connect google drive before runing the code\n",
        "3. run the code.\n",
        "4.you can test enhanced image by code mention lin last code cell"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "9A958K-Y9Mpx"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQafxoSHg50k"
      },
      "source": [
        "### install dependencies like tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xlUzs1RpgpbJ"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QaivWeyvhIF6"
      },
      "source": [
        "### Connect Google drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AN2TAU360DgE"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!ls /content/drive/MyDrive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtDBPuvahMqM"
      },
      "source": [
        "### Complete code to run "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_LIPNOVe0CjO"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import keras\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import lite\n",
        "import tensorflow as tf\n",
        "# load and evaluate a saved model\n",
        "import numpy as np\n",
        "from keras.models import load_model\n",
        "from keras.preprocessing import image\n",
        "from matplotlib import pyplot as plt\n",
        "import cv2\n",
        "import os\n",
        "from google.colab.patches import cv2_imshow\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
        "from sklearn import preprocessing\n",
        "from keras.layers import Conv2D, Dense, Flatten, MaxPool2D, Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "import math\n",
        "from keras.preprocessing import image\n",
        "from PIL import Image\n",
        "from matplotlib import cm\n",
        "from PIL import ImageEnhance\n",
        "import io\n",
        "import numpy as np\n",
        "from keras.layers import Input\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Convolution2D\n",
        "from keras.models import Model\n",
        "from keras.layers import GlobalAveragePooling2D,MaxPooling2D\n",
        "from keras.layers import Dense,Flatten,SpatialDropout2D\n",
        "from keras.layers.merge import concatenate\n",
        "\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.callbacks import History\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import pandas as pd\n",
        "%matplotlib inline\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import KFold, cross_val_score\n",
        "from sklearn.metrics import r2_score, roc_auc_score, roc_curve\n",
        "from scipy import stats  # For in-built method to get PCC\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "class Diabatic_Retino_Detection():\n",
        "    def __init__(self, dataset_path=\"/content/drive/MyDrive/retinopathy-dataset\",enhanceddataset_path=\"/content/drive/MyDrive/newretinopathy-dataset\",data_path=\"/content/drive/MyDrive/\",models_path=\"'/content/drive/MyDrive/model/'\"):\n",
        "        self.dataset_path  = dataset_path\n",
        "        self.enhanceddataset_path=enhanceddataset_path\n",
        "        self.models_path=models_path\n",
        "        self.data_path=data_path\n",
        "        self.predictionsclasses = ['nosymptoms', 'symptoms']\n",
        "\n",
        "#---------------Image acquisition per image---------- details: it read image and convert it into digital , do shaping and resizing etc.\n",
        "    def image_acquisition(self,image_file, gray_scale=False):\n",
        "        image_src= cv2.imread( image_file)\n",
        "        if gray_scale:\n",
        "          image_rgb = cv2.cvtColor(image_src, cv2.COLOR_BGR2GRAY)\n",
        "        else:\n",
        "          image_rgb = cv2.cvtColor(image_src, cv2.COLOR_BGR2RGB)\n",
        "        TARGET_PIXEL_AREA = 100000.0\n",
        "        img=image_rgb\n",
        "        ratio = float(img.shape[1]) / float(img.shape[0])\n",
        "        new_h = int(math.sqrt(TARGET_PIXEL_AREA / ratio) + 0.5)\n",
        "        new_w = int((new_h * ratio) + 0.5)\n",
        "        img2 = cv2.resize(img, (new_w,new_h))\n",
        "        return img2\n",
        "\n",
        "#---------------Image enhance contrast per image---------- details: it it enhance the contrast in per image it is a sub function of function mentioned below this function etc.\n",
        "    def enhance_contrast(self,image_matrix, bins=256):\n",
        "        image_flattened = image_matrix.flatten()\n",
        "        image_hist = np.zeros(bins)\n",
        "\n",
        "        # frequency count of each pixel\n",
        "        for pix in image_matrix:\n",
        "            image_hist[pix] += 1\n",
        "\n",
        "        # cummulative sum\n",
        "        cum_sum = np.cumsum(image_hist)\n",
        "        norm = (cum_sum - cum_sum.min()) * 255\n",
        "        # normalization of the pixel values\n",
        "        n_ = cum_sum.max() - cum_sum.min()\n",
        "        uniform_norm = norm / n_\n",
        "        uniform_norm = uniform_norm.astype('int')\n",
        "\n",
        "        # flat histogram\n",
        "        image_eq = uniform_norm[image_flattened]\n",
        "        # reshaping the flattened matrix to its original shape\n",
        "        image_eq = np.reshape(a=image_eq, newshape=image_matrix.shape)\n",
        "\n",
        "        return image_eq\n",
        "\n",
        "#---------------Image equalize per image---------- details: it it enhance and equalize per image and preprocess it for next step of reshaping for dataset etc.\n",
        "    def equalize_this(self,image_file,saveimage_file, with_plot=False, gray_scale=False, bins=256):\n",
        "        image_src = self.image_acquisition(image_file, gray_scale=False)\n",
        "        if not gray_scale:\n",
        "            r_image = image_src[:, :, 0]\n",
        "            g_image = image_src[:, :, 1]\n",
        "            b_image = image_src[:, :, 2]\n",
        "\n",
        "            r_image_eq = self.enhance_contrast(image_matrix=r_image)\n",
        "            g_image_eq = self.enhance_contrast(image_matrix=g_image)\n",
        "            b_image_eq = self.enhance_contrast(image_matrix=b_image)\n",
        "\n",
        "            image_eq = np.dstack(tup=(r_image_eq, g_image_eq, b_image_eq))\n",
        "            cmap_val = None\n",
        "        else:\n",
        "            image_eq = self.enhance_contrast(image_matrix=image_src)\n",
        "            cmap_val = 'gray'\n",
        "\n",
        "        #if with_plot:\n",
        "        fig = plt.figure(figsize=(10, 20))\n",
        "\n",
        "        #ax1 = fig.add_subplot(2, 2, 1)\n",
        "        #ax1.axis(\"off\")\n",
        "        #ax1.title.set_text('Original')\n",
        "        #ax2 = fig.add_subplot(2, 2, 2)\n",
        "        #ax2.axis(\"off\")\n",
        "        #ax2.title.set_text(\"Equalized\")\n",
        "\n",
        "        #ax1.imshow(image_src, cmap=cmap_val)\n",
        "        #ax2.imshow(image_eq, cmap=cmap_val)\n",
        "        plt.imsave(saveimage_file, np.uint8(image_eq), cmap=cmap_val)\n",
        "                    # load the image\n",
        "        image = Image.open(saveimage_file)\n",
        "            # convert image to numpy array\n",
        "        data = np.asarray(image)\n",
        "        #print(type(data))\n",
        "            # summarize shape\n",
        "        #print(data.shape)\n",
        "\n",
        "            # create Pillow image\n",
        "        image2 = Image.fromarray(data)\n",
        "        #print(type(image2))\n",
        "\n",
        "        # summarize image details\n",
        "        #print(image2.mode)\n",
        "        #print(image2.size)\n",
        "        #print(type(image2))\n",
        "        #img = Image.open(fh, mode='r')\n",
        "        roi_img = image2\n",
        "\n",
        "        img_byte_arr = io.BytesIO()\n",
        "        roi_img.save(img_byte_arr, format='jpeg')\n",
        "        img_byte_arr = img_byte_arr.getvalue()\n",
        "        #print(type(img_byte_arr))\n",
        "        return img_byte_arr\n",
        "\n",
        "#---------------Image reshaping per image---------- details: it reshape the image array to store in dataset.\n",
        "    def image_reshaping(self,image):\n",
        "        #new_im = Image.fromarray(image)\n",
        "        new_im = np.array(image)\n",
        "        return new_im\n",
        "\n",
        "#---------------Imagedata preprocessing ---------- details: this function convert all the input dataset images into enhance images and save image arrays of byte and extract labels and save them into .\n",
        "    def imagedata_preprocessing(self):\n",
        "        print(\"Image Data preprocessing started...\")\n",
        "        print(\"Image Data acquisition started...\")\n",
        "        # preprocessing\n",
        "        imgs_path = self.dataset_path\n",
        "        data = []\n",
        "        labels = []\n",
        "        labelclasses = os.listdir(imgs_path)\n",
        "        for labelclass in labelclasses:\n",
        "            img_path = os.path.join(imgs_path, str(labelclass))  # 0-42\n",
        "            saveimg_path = os.path.join(self.enhanceddataset_path, str(labelclass))  # 0-42\n",
        "            imgs =os.listdir(img_path)\n",
        "            for img in imgs:\n",
        "                image_file=img_path+'/'+img\n",
        "                saveimagefile=saveimg_path+'/'+img\n",
        "                #image_file=os.path.join(imgs_path, img)\n",
        "                image_eq=self.equalize_this(image_file,saveimagefile, with_plot=False, gray_scale=False, bins=256)\n",
        "                im = self.image_reshaping(image_eq)\n",
        "                data.append(im)\n",
        "                labels.append(labelclass)\n",
        "                print('label',labelclass,'filename',img)\n",
        "        print(\"Image Data successfully preprocessed\")\n",
        "        self.data = data\n",
        "        self.labels = labels\n",
        "\n",
        "#---------------Imagedata preprocessing ---------- details:this function convert imagedataset array return by preprocessing funtion into numpy array and change the categorical labels into numeric this process is called transformation of data for modeling purpose.\n",
        "    def imagedata_transformation(self):\n",
        "        #print(self.data)\n",
        "        #x_train= np.asarray(self.data)\n",
        "        #y_train = np.asarray(self.labels)\n",
        "        #print(\"training shape: \", x_train.shape, y_train.shape)\n",
        "        #le = preprocessing.LabelEncoder()\n",
        "        #y_train=le.fit_transform(y_train)\n",
        "        #self.x_train= x_train\n",
        "        #self.y_train=y_train\n",
        "        train_data_path = self.enhanceddataset_path\n",
        "        train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                      rotation_range=40,\n",
        "                                      width_shift_range=0.2,\n",
        "                                      height_shift_range=0.2,\n",
        "                                      shear_range=0.2,\n",
        "                                      zoom_range=0.2,\n",
        "                                      validation_split=0.2,\n",
        "                                      horizontal_flip=True,\n",
        "                                      fill_mode='nearest')\n",
        "        training_data = train_datagen.flow_from_directory(train_data_path, \n",
        "                                      target_size=(150,150),\n",
        "                                      batch_size=32,\n",
        "                                      class_mode='binary',\n",
        "                                      subset='training')\n",
        "        valid_data = train_datagen.flow_from_directory(train_data_path, \n",
        "                                      target_size=(150,150),\n",
        "                                      batch_size=32,\n",
        "                                      class_mode='binary',\n",
        "                                      subset='validation')\n",
        "\n",
        "        for i in os.listdir(train_data_path):\n",
        "          print(str(len(os.listdir(train_data_path+'/'+i))) +\" \"+ i +\" images\")\n",
        "        \n",
        "        self.training_data=training_data\n",
        "        self.valid_data=valid_data\n",
        "        self.valid_datax=valid_data[0][0]\n",
        "        self.valid_datalabels= valid_data.labels\n",
        "        self.valid_dataclasses= valid_data.class_indices.keys()\n",
        "        #print(valid_data[0][0])\n",
        "        print('Image data transformation done successfully.')\n",
        "\n",
        "#---------------CNN Model configration---------- details: this function is about model configuration in which we set model checkpoints set number of epochs number of layers and type of layer number of outputs and number of iterations in model and model path .\n",
        "    def model_configration(self):\n",
        "        image_size = (64, 64)\n",
        "        print(\"Convolutional Model configration started...\")\n",
        "        model_path = self.models_path+'test.h5'\n",
        "        print(model_path)\n",
        "        model = keras.models.Sequential([\n",
        "                                    keras.layers.Conv2D(filters=32, kernel_size=3, input_shape=[150, 150, 3]),\n",
        "                                    keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
        "                                    keras.layers.Conv2D(filters=64, kernel_size=3),\n",
        "                                    keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
        "                                    keras.layers.Conv2D(filters=128, kernel_size=3),\n",
        "                                    keras.layers.MaxPooling2D(pool_size=(2,2)),                                    \n",
        "                                    keras.layers.Conv2D(filters=256, kernel_size=3),\n",
        "                                    keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
        " \n",
        "                                    keras.layers.Dropout(0.5),                                                                        \n",
        "                                    keras.layers.Flatten(), \n",
        "                                    keras.layers.Dense(units=128, activation='relu'), \n",
        "                                    keras.layers.Dropout(0.1),                                    \n",
        "                                    keras.layers.Dense(units=256, activation='relu'),                                    \n",
        "                                    keras.layers.Dropout(0.25),                                    \n",
        "                                    keras.layers.Dense(units=2, activation='softmax') ])\n",
        "        model.compile(optimizer = Adam(lr=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "        model.summary()\n",
        "        print(\"Convolutional Model successfully configured.\")\n",
        "        self.model=model\n",
        "#---------------CNN model Performance graph---------- details: this function is about  for performance and evaluation graphs .   \n",
        "    def plot_model_history(self,history):\n",
        "        #history=self.history\n",
        "        print(history.history.keys())\n",
        "        # summarize history for accuracy\n",
        "        plt.plot(history.history['accuracy'])\n",
        "        plt.plot(history.history['val_accuracy'])\n",
        "        plt.title('model accuracy')\n",
        "        plt.ylabel('accuracy')\n",
        "        plt.xlabel('epoch')\n",
        "        plt.legend(['train', 'test'], loc='upper left')\n",
        "        plt.show()\n",
        "\n",
        "        plt.plot(history.history['loss'])\n",
        "        plt.plot(history.history['val_loss'])\n",
        "        plt.title('model loss')\n",
        "        plt.ylabel('loss')\n",
        "        plt.xlabel('epoch')\n",
        "        plt.legend(['train', 'test'], loc='upper left')\n",
        "        plt.show()\n",
        "#---------------model testing performance graphs---------- details: this function test image after enhancing and show the labels .   \n",
        "    def results(self,target_test, predicted_test,ModelName,labels):\n",
        "       target_names = labels\n",
        "       print(classification_report(target_test, predicted_test, target_names=target_names))\n",
        "       y_test = target_test\n",
        "       preds = predicted_test\n",
        "       rms = np.sqrt(np.mean(np.power((np.array(y_test) - np.array(preds)), 2)))\n",
        "       score = r2_score(y_test, preds)\n",
        "       mae = mean_absolute_error(y_test, preds)\n",
        "       mse = mean_squared_error(y_test, preds)\n",
        "       pearson_coef, p_value = stats.pearsonr(y_test, preds)\n",
        "\n",
        "       print(\"root mean square:\", rms)\n",
        "       print(\"score:\", score)\n",
        "       print(\"mean absolute error:\", mae)\n",
        "       print(\"mean squared error:\", mse)\n",
        "       print(\"pearson_coef:\", pearson_coef)\n",
        "       print(\"p_value:\", p_value)\n",
        "       print(\"=======================================================================\\n\\n\")\n",
        "       skplt.metrics.plot_confusion_matrix(\n",
        "        y_test,\n",
        "        preds,\n",
        "        figsize=(10, 6), title=\"Confusion matrix\\n Deposite Category \"+ModelName)\n",
        "       plt.xlim(-0.5, len(np.unique(y_test)) - 0.5)\n",
        "       plt.ylim(len(np.unique(y_test)) - 0.5, -0.5)\n",
        "       plt.savefig('cvroc.png')\n",
        "       plt.show()\n",
        "\n",
        "#---------------CNN model training---------- details: this function is about training model by giving input training dataset and labels which we got from above funcitons and set validation ratio 0.2 for performance and evaluation .\n",
        "    def train_model(self):\n",
        "        print(\"Convolutional Model training started...\")\n",
        "        training_data=self.training_data\n",
        "        valid_data=self.valid_data\n",
        "        model= self.model\n",
        "        history = History()\n",
        "        callbacks = [EarlyStopping(monitor='val_loss', patience=5),ModelCheckpoint(filepath=self.models_path+'best_model.h5', monitor='val_loss', save_best_only=True),history]\n",
        "        history = model.fit_generator(training_data,\n",
        "                                      steps_per_epoch = 8000/32,\n",
        "                                      epochs = 1000,\n",
        "                                      validation_data = valid_data,\n",
        "                                      validation_steps = 64,\n",
        "                                      use_multiprocessing = True,\n",
        "                                      workers = 8,\n",
        "                                      callbacks=callbacks)\n",
        "        \n",
        "        self.plot_model_history(history)\n",
        "        model.save(self.models_path+'model.hd5')\n",
        "        print(\"Convolutional Model successfully trained.\")\n",
        "        print(\"Convolutional Model Performance & testing results\")\n",
        "        plt.plot(history.history['accuracy'])\n",
        "        plt.plot(history.history['val_accuracy'])\n",
        "        plt.title('model accuracy')\n",
        "        plt.ylabel('accuracy')\n",
        "        plt.xlabel('epoch')\n",
        "        plt.legend(['train', 'test'], loc='upper left')\n",
        "        plt.show()\n",
        "\n",
        "        plt.plot(history.history['loss'])\n",
        "        plt.plot(history.history['val_loss'])\n",
        "        plt.title('model loss')\n",
        "        plt.ylabel('loss')\n",
        "        plt.xlabel('epoch')\n",
        "        plt.legend(['train', 'test'], loc='upper left')\n",
        "        plt.show()\n",
        "        self.history=history\n",
        "        test_datax= self.valid_datax\n",
        "        predicted_test=model.fit(test_datax)\n",
        "        target_test=self.valid_datalabels\n",
        "        ModelName= \"Convolutional Neural Network\"\n",
        "        labels=self.valid_dataclasses\n",
        "        self.results(target_test, predicted_test,ModelName,labels)\n",
        "\n",
        "    def train_previousmodel(self):\n",
        "        print(\"Convolutional Model training started...\")\n",
        "        model_path='/content/drive/MyDrive/model/model.hd5'\n",
        "        model = load_model(model_path)\n",
        "        training_data=self.training_data\n",
        "        valid_data=self.valid_data\n",
        "        #model= self.model\n",
        "        history = History()\n",
        "        callbacks = [EarlyStopping(monitor='val_loss', patience=5),ModelCheckpoint(filepath=self.models_path+'best_model.h5', monitor='val_loss', save_best_only=True),history]\n",
        "        history = model.fit_generator(training_data,\n",
        "                                      steps_per_epoch = 8000/32,\n",
        "                                      epochs = 1000,\n",
        "                                      validation_data = valid_data,\n",
        "                                      validation_steps = 64,\n",
        "                                      use_multiprocessing = True,\n",
        "                                      workers = 8,\n",
        "                                      callbacks=callbacks)\n",
        "        \n",
        "        self.plot_model_history(history)\n",
        "        model.save(model_path)\n",
        "        history\n",
        "        print(\"Convolutional Model successfully trained.\")\n",
        "        print(\"Convolutional Model Performance & testing results\")\n",
        "        plt.plot(history.history['accuracy'])\n",
        "        plt.plot(history.history['val_accuracy'])\n",
        "        plt.title('model accuracy')\n",
        "        plt.ylabel('accuracy')\n",
        "        plt.xlabel('epoch')\n",
        "        plt.legend(['train', 'test'], loc='upper left')\n",
        "        plt.show()\n",
        "\n",
        "        plt.plot(history.history['loss'])\n",
        "        plt.plot(history.history['val_loss'])\n",
        "        plt.title('model loss')\n",
        "        plt.ylabel('loss')\n",
        "        plt.xlabel('epoch')\n",
        "        plt.legend(['train', 'test'], loc='upper left')\n",
        "        plt.show()\n",
        "        self.history=history\n",
        "        test_datax= self.valid_datax\n",
        "        predicted_test=model.fit(test_datax)\n",
        "        target_test=self.valid_datalabels\n",
        "        ModelName= \"Convolutional Neural Network\"\n",
        "        labels=self.valid_dataclasses\n",
        "        self.results(target_test, predicted_test,ModelName,labels)\n",
        "#---------------hd5 model to tf lite model conversion---------- details: this function converts the model into tf lite version for lite applications .     \n",
        "    def convert_hd5model_to_tflite(self):\n",
        "        print(\"Convolutional Model conversion from to tflite started...\")\n",
        "        models = tf.keras.models.load_model('/content/drive/MyDrive/model/model.hd5')\n",
        "        converter = lite.TFLiteConverter.from_keras_model(models)\n",
        "        print(converter)\n",
        "        model = converter.convert()\n",
        "        tfmodel_path=self.models_path+'model.tflite'\n",
        "        assert isinstance(model, object)\n",
        "        file = open(tfmodel_path, 'wb').write(model)\n",
        "        print(\"Convolutional Model successfully converted from to tflite...\")\n",
        "\n",
        "#---------------model testing---------- details: this function test image after enhancing and show the labels .          \n",
        "    def test_model(self,Image_test_path):\n",
        "        print(\"Image testing started...\")\n",
        "        # load model\\\n",
        "        model_path=self.models_path+'model.hd5'\n",
        "        model = load_model(model_path)\n",
        "        # summarize model.\n",
        "        # model.summary()\n",
        "        # load dataset\n",
        "        image1 = image.load_img(Image_test_path, target_size=(150, 150))\n",
        "        image1.save('test.jpeg')\n",
        "        # image1\n",
        "        #input_arr = image.img_to_array(image1)\n",
        "        image1=self.equalize_this('test.jpeg','test.jpeg' , with_plot=False, gray_scale=False, bins=256)\n",
        "        input_arr = self.image_reshaping(image1) # Convert single image to a batch\n",
        "        #input_arr = image.img_to_array(input_arr)\n",
        "        #input_arr\n",
        "        predictions1 = model.predict(input_arr)\n",
        "        print(predictions1)\n",
        "        probabilities1 = model.predict_proba(input_arr)\n",
        "        print(probabilities1)\n",
        "        predictionsclasses = self.predictionsclasses\n",
        "        probabilitiestest = list(probabilities1)\n",
        "        testprob = max(probabilitiestest)\n",
        "        print(testprob.tolist())\n",
        "        max_value = max(testprob)\n",
        "        print(max_value)\n",
        "        for i in range(len(testprob)):\n",
        "            if testprob[i] == max_value:\n",
        "                max_index = i\n",
        "                print(predictionsclasses[max_index])\n",
        "        print(\"Image testing successfully completed.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    Diabatic_Retino_Detection = Diabatic_Retino_Detection()\n",
        "    #Diabatic_Retino_Detection.imagedata_preprocessing()\n",
        "    Diabatic_Retino_Detection.imagedata_transformation()\n",
        "    Diabatic_Retino_Detection.model_configration()\n",
        "    Diabatic_Retino_Detection.train_model()\n",
        "    #Diabatic_Retino_Detection.train_previousmodel()\n",
        "    Image_test1 = '/content/drive/MyDrive/retinopathy-dataset/nosymptoms/10265_left.jpeg'\n",
        "    Image_test2 = '/content/drive/MyDrive/retinopathy-dataset/nosymptoms/10643_left.jpeg'\n",
        "    Image_test3 = '/content/drive/MyDrive/retinopathy-dataset/symptoms/10030_left.jpeg'\n",
        "    Image_test4 = '/content/drive/MyDrive/retinopathy-dataset/symptoms/10030_right.jpeg'\n",
        "    Diabatic_Retino_Detection.test_model(Image_test1)\n",
        "    Diabatic_Retino_Detection.test_model(Image_test2)\n",
        "    Diabatic_Retino_Detection.test_model(Image_test3)\n",
        "    Diabatic_Retino_Detection.test_model(Image_test4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wyV0Bb6G2Zk"
      },
      "source": [
        "### code to test the image enhancement process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zFTHTRiKKBnZ"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import cv2\n",
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from matplotlib import cm\n",
        "import math\n",
        "# load a fundus image, normalized into 0-1 range (not 0-255)\n",
        "# such as one from the IDRiD dataset  (assuming you already have it on disk)\n",
        "#dset = IDRiD('./data/IDRiD_segmentation')\n",
        "#img_id, img, labels = dset.sample()\n",
        "#print(\"using image\", img_id)\n",
        "#import cv2\n",
        "\n",
        "def read_this(image_file, gray_scale=False):\n",
        "    image_src = cv2.imread(image_file)\n",
        "    print(type(image_src))\n",
        "    if gray_scale:\n",
        "        image_rgb = cv2.cvtColor(image_src, cv2.COLOR_BGR2GRAY)\n",
        "    else:\n",
        "        image_rgb = cv2.cvtColor(image_src, cv2.COLOR_BGR2RGB)\n",
        "    TARGET_PIXEL_AREA = 100000.0\n",
        "    img=image_rgb\n",
        "    ratio = float(img.shape[1]) / float(img.shape[0])\n",
        "    new_h = int(math.sqrt(TARGET_PIXEL_AREA / ratio) + 0.5)\n",
        "    new_w = int((new_h * ratio) + 0.5)\n",
        "    img2 = cv2.resize(img, (new_w,new_h))\n",
        "    print(type(img2))\n",
        "    return img2\n",
        "def enhance_contrast(image_matrix, bins=256):\n",
        "    image_flattened = image_matrix.flatten()\n",
        "    image_hist = np.zeros(bins)\n",
        "\n",
        "    # frequency count of each pixel\n",
        "    for pix in image_matrix:\n",
        "        image_hist[pix] += 1\n",
        "\n",
        "    # cummulative sum\n",
        "    cum_sum = np.cumsum(image_hist)\n",
        "    norm = (cum_sum - cum_sum.min()) * 255\n",
        "    # normalization of the pixel values\n",
        "    n_ = cum_sum.max() - cum_sum.min()\n",
        "    uniform_norm = norm / n_\n",
        "    uniform_norm = uniform_norm.astype('int')\n",
        "\n",
        "    # flat histogram\n",
        "    image_eq = uniform_norm[image_flattened]\n",
        "    # reshaping the flattened matrix to its original shape\n",
        "    image_eq = np.reshape(a=image_eq, newshape=image_matrix.shape)\n",
        "    print(type(image_eq))\n",
        "    return image_eq\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "def demorgb(image,colormap):\n",
        "  # Get the color map by name:\n",
        "  \n",
        "  cm = plt.get_cmap(colormap)\n",
        "  # Apply the colormap like a function to any array:\n",
        "  colored_image = cm(image)\n",
        "  # Obtain a 4-channel image (R,G,B,A) in float [0, 1]\n",
        "  # But we want to convert to RGB in uint8 and save it:\n",
        "  imageeq =Image.fromarray((colored_image[:, :, :3] * 255).astype(np.uint8))\n",
        "  return imageeq\n",
        "\n",
        "def equalize_this(image_file, with_plot=False, gray_scale=False, bins=256):\n",
        "    image_src = read_this(image_file=image_file, gray_scale=gray_scale)\n",
        "    if not gray_scale:\n",
        "        r_image = image_src[:, :, 0]\n",
        "        g_image = image_src[:, :, 1]\n",
        "        b_image = image_src[:, :, 2]\n",
        "\n",
        "        r_image_eq = enhance_contrast(image_matrix=r_image)\n",
        "        g_image_eq = enhance_contrast(image_matrix=g_image)\n",
        "        b_image_eq = enhance_contrast(image_matrix=b_image)\n",
        "\n",
        "        image_eq = np.dstack(tup=(r_image_eq, g_image_eq, b_image_eq))\n",
        "        cmap_val = None\n",
        "    else:\n",
        "        image_eq = enhance_contrast(image_matrix=image_src)\n",
        "        cmap_val = 'gray'\n",
        "\n",
        "    if with_plot:\n",
        "        fig = plt.figure(figsize=(10, 20))\n",
        "\n",
        "        ax1 = fig.add_subplot(2, 2, 1)\n",
        "        ax1.axis(\"off\")\n",
        "        ax1.title.set_text('Original')\n",
        "        ax2 = fig.add_subplot(2, 2, 2)\n",
        "        ax2.axis(\"off\")\n",
        "        ax2.title.set_text(\"Equalized\")\n",
        "\n",
        "        ax1.imshow(image_src, cmap=cmap_val)\n",
        "        plt.imsave('test.png', image_src, cmap=cmap_val)\n",
        "        image_eq=ax2.imshow(image_eq, cmap=cmap_val)\n",
        "        plt.imsave('test.png', image_src, cmap=cmap_val)\n",
        "        from PIL import Image\n",
        "        from numpy import asarray\n",
        "        # load the image\n",
        "        image = Image.open('test.png')\n",
        "        # convert image to numpy array\n",
        "        data = asarray(image)\n",
        "        print(type(data))\n",
        "        # summarize shape\n",
        "        print(data.shape)\n",
        "\n",
        "        # create Pillow image\n",
        "        image2 = Image.fromarray(data)\n",
        "        print(type(image2))\n",
        "\n",
        "        # summarize image details\n",
        "        print(image2.mode)\n",
        "        print(image2.size)\n",
        "\n",
        "        return True\n",
        "    print(type(image2))\n",
        "    return image2\n",
        "a=equalize_this(image_file='/content/drive/MyDrive/retinopathy-dataset/nosymptoms/10265_left.jpeg', with_plot=True)\n",
        "print(a)\n",
        "path=\"C:\\\\Somewhere\\\\myproperdirectory\\\\\"\n",
        "#from skimage.io._plugins.pil_plugin import ndarray_to_pil, pil_to_ndarray\n",
        "#im=ndarray_to_pil(a).convert(\"1\")\n",
        "#a.save(\"your_file.jpeg\")\n",
        "#data = np.asarray( img, dtype=\"int32\" )\n",
        "#img = Image.fromarray( np.asarray( np.clip(data,0,255), dtype=\"uint8\"), \"L\" )\n",
        "#image1 = cv2.imread( 'test.png')\n",
        "#input_arr = image.img_to_array(a)\n",
        "input_arr = np.array([a])\n",
        "print(type(input_arr))\n",
        "input_arr=input_arr.flatten()\n",
        "print(type(input_arr))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mB2tnaym41wh"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "#plt.savefig(\"/content/test.png\")\n",
        "files.upload()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zt4QIsER4kf5"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}